# Cerebras 

## Connection to a CS-2 node

Connection to one of the CS-2 cluster login nodes requires an MFA passcode for authentication - either an 8-digit passcode generated by an app on your mobile device (e.g. MobilePASS+) or a CRYPTOCard-generated passcode prefixed by a 4-digit pin. This is the same passcode used to authenticate into other ALCF systems, such as Theta and Cooley.

![CS-2 connection diagram](./Cerebras_Wafer-Scale_Cluster_login_diagram.png)

To connect to a CS-2 login, ssh to login nodes:
```bash
ssh ALCFUserID@cerebras.ai.alcf.anl.gov
```

## Prerequisite: Create Virtual Environment 

### PyTorch virtual environment

```bash
#Make your home directory navigable
chmod a+xr ~/
mkdir ~/R_2.1.1
chmod a+x ~/R_2.1.1/
cd ~/R_2.1.1
# Note: "deactivate" does not actually work in scripts.
deactivate
rm -r venv_cerebras_pt
/software/cerebras/python3.8/bin/python3.8 -m venv venv_cerebras_pt
source venv_cerebras_pt/bin/activate
pip install --upgrade pip
pip install cerebras_pytorch==2.1.1
```

## Clone Cerebras modelzoo

We use an example from [Cerebras Modelzoo repository](https://github.com/Cerebras/modelzoo) for this hands-on. 

* Clone the modezoo repository.<br>
```bash
mkdir ~/R_2.1.1
cd ~/R_2.1.1
git clone https://github.com/Cerebras/modelzoo.git
cd modelzoo
git tag
git checkout Release_2.1.1    
```
* Install requirements for modelzoo
    ```bash
    cd ~/R_2.1.1/modelzoo
    pip install -r requirements.txt 
    ```

## Job Queuing and Submission

The CS-2 cluster has its own Kubernetes-based system for job submission and queuing. Jobs are started automatically through the Python scripts. 

Use Cerebras cluster command line tool to get addional information about the jobs.

* Jobs that have not yet completed can be listed as
    `(venv_pt) $ csctl get jobs`
* Jobs can be canceled as shown:
    `(venv_tf) $ csctl cancel job wsjob-eyjapwgnycahq9tus4w7id`

See `csctl -h` for more options.

## Hands-on Example

* [BERT](./bert-large.md)

## Homework

Run BERT example with different batch sizes like 512, 2048 and observe the performance difference.  

BERT with batch size 1024 
![image](https://github.com/user-attachments/assets/4560fc8b-30eb-4924-b33d-09b6dc5c6b6f)

BERT with batch size 512
![image](https://github.com/user-attachments/assets/43299938-3236-4b5c-9f24-9e508774b4fe)


### Additional Examples (Optional)

* [GPT-J](./gptj.md)
* [GPT-2](./gpt2.md)

# Useful Resources 

* [ALCF Cerebras Documentation](https://docs.alcf.anl.gov/ai-testbed/cerebras/system-overview/)
* [Cerebras Documntation](https://docs.cerebras.net/en/latest/wsc/index.html)
* [Cerebras Modelzoo Repo](https://github.com/Cerebras/modelzoo/tree/main/modelzoo)
* Datasets Path: `/software/cerebras/dataset`
